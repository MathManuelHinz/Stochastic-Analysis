\chapter{Local times, Itô-Tanaka formula, reflected Brownian Motion}

\section{Extension of Itô formula to convex functions}

If $f\in C^2(\R), f(X_t)=f(X_0)+\int_0^t f'(X_s)dX_s+\frac{1}{2}\int_0^t f''(X_s)d\langle x\rangle_s$

\begin{proposition}\label{prop:3.1}
    Let $f$ be a convex function on $\R$, $X_t$ a (continuous) semimartingale, 
    then $f(X_t)$ is a semimartingale: $\exists A_t^f$ such that $\forall t\geq 0$\marginnote{We make a choice for the left derivative, the same works for the right one, but with different processes}
    \[f(X_t)=f(X_0)+\int_{0}^t \underbrace{f_-'}_{\text{left derivative of }f}(X_s)dX_s+A_t^f\]
\end{proposition}

\begin{remark}
    This extends directly to the case that $f=f_1-f_2$ with $f_1,f_2$ convex (But with bounded variation and not necessarily increasing $A_t^f$)
\end{remark}

\begin{proof}[Sketch of Proof]
    Consider a function $\rho(x)$ s.t. 
    \begin{itemize}
        \item $\rho(x)\geq 0$, $\rho$ smooth
        \item $\rho(x)=0$ if $x\notin [0,1]$
        \item $\int_0^1 \rho(x)dx=1$
    \end{itemize}
    For any $n\in\N$ set 
    \[f_n(x)\coloneqq\int_\R n\rho(ny)f(x-y)dy\]
    Verify:
    \begin{itemize}
        \item $f_n$ is $C^2(\R)$; $f_n''\geq 0$ (since $f$ is convex)
        \item $f_n'(x)=\int_\R n\rho(ny)\cdot f_-'(x-y)dy$
        \item $f_n(x)\stackrel{n\to\infty}{\to} f(x)$
        \item $f_n'(x)\stackrel{n\to\infty}{\to} f_-'(x)$ \marginnote{left derivative since we do convolution and not correlation with $\rho$}
    \end{itemize}
    Itô formula to $f_n(X_t)$:
    \[f_n(X_t)=f_n(X_0)+\int_0^t f_n'(X_s)dX_s +\underbrace{\frac{1}{2}\int_0^t f_n''(X_s)\langle X\rangle_s}_{A_t^{f_n}\in \mathcal{A}_+^0}\]

    Using stopping times: If $X=\underbrace{M_+}_{\in \Mloc^0}+\underbrace{A}_{\in\cA}$

    $\forall m\geq 1: T_m=\inf\{t\geq 0\mid |X_t|+\langle M \rangle_t +\int_0^t |dA_s|\geq m\}$

    \[f_n(X_{t\land T_m})=f(X_0)+\underbrace{\int_0^{t\land T_m}f_n'(X_s)dX_s}_{\stackrel{n\to\infty,\bP}{\to}\int_0^{t\land T_m}f_-'(X_s)dX_s}+\underbrace{\frac{1}{2}\int_0^{t\land T_m}f_n''(X_s)d\langle M\rangle_s}_{A_{t\land T_m}^{f_n}}\]

    $\implies$ set $A_t^{f,m}\coloneqq f(X_{t\land T_m})-f(X_0)-\int_0^{T_m} f_-'(X_s)dX_s$ and 
    $A_{t\land T_m}^{f_n}\stackrel{n\to\infty,\bP}{\to}A_t^{f,m}=A_{t\land T_m}^f$; Take $m\to\infty$ and get a process $A_t^f$ since 
    $f_n''\geq 0\implies A_t^f$ is increasing and in $\cA_0$.\qedhere
\end{proof}

Let $f(x)=|x|$. Then 
\[f_-'(x)=\begin{cases}
    -1 & x\leq 0\\
    1 & x>0
\end{cases}\]
we therefore define 
\[\text{sgn}(x)\coloneqq\begin{cases}
    -1 & x\leq 0\\
    1 & x>0
\end{cases}\]

as the left derivative of $|x|$.

\begin{proposition}[Tanaka's formula]\label{prop:3.2}
    Let $X$ be a continuous semimartingale and $a\in\R$. Then there $\exists$ increasing process 
    $(L_t^a(X))_{t\geq 0}$ s.t.:
    \begin{enumerate}
        \item[(a)] $|X_t-a|=|X_0-a|+\int_{0}^t\sgn(X_s-a)dX_s+L_t^a(X)$
        \item[(b)] $(X_t-a)^+ = (X_0-a)^++\int_0^t 1_{X_s>a}dX_s+\frac{1}{2}L_t^a(X)$
        \item[(c)] $(X_t-a)^- = (X_0-a)^--\int_0^t 1_{X_s\leq a}dX_s+\frac{1}{2}L_t^a(X)$
    \end{enumerate}
    The process $L_t^a(X)$ is called the \dhighlight{local time of $X$} at \dhighlight{level $a$}.
    For any stopping time $T$:\[L_t^a(X^T)=L_{t\land T}^a(X)\]
\end{proposition}

\begin{proof}
    Taking $f(x)=|x-a|$ in proposition \ref{prop:3.1} yields (a). Therefore 
    \[L_t^a(X)\coloneqq |X_t-a|-|X_0-a|-\int_0^t\sgn(X_s-a)dX_s\]
    Applying prop. \ref{prop:3.1} to $f(x)=(x-a)^+$ and $f(x)=(x-a)^-$
    \[\implies \exists A_t^{a,(+)},A_t^{a,(-)}\in \cA_0^+\]
    such that 
    \[(X_t-a)^+=(X_0-a)^+\int_0^t 1_{X_s>a}dX_s A_t^{a,(+)}\]
    \[(X_t-a)^-=(X_0-a)^-\int_0^t 1_{X_s\leq a}dX_s A_t^{a,(-)}\]

    \begin{align*}
        X_t-a&\stackrel{\text{Itô}}{=}X_0-a+\int_0^tdX_s\\
        X_t-a&=(X_t-a)^+-(X_t-a)^-=X_0-a+\int_0^t dX_s + A_t^{a,(+)}- A_t^{a,(-)}
    \end{align*}
    which holds if and only if $ A_t^{a,(+)}= A_t^{a,(-)}$.
    Furthermore 
    \[|X_t-a|=|X_0-a|+\int_0^1\sgn(X_s-a)dX_s+ \underbrace{A_t^{a,(+)}+ A_t^{a,(-)}}_{=L_t^a(X)}\qedhere\]

\end{proof}

\underline{To see:} $L_t^a(X)\to$ positive measure $dL_t^a(X)$, since $L_t^a(X)$ is increasing.
\begin{align*}
    \int_0^t \underbrace{f(x)}_{\geq 0}dL_s^a(X)\stackrel{\text{?}}{=}0\text{ if } f(x)>0\text{ for } x\neq a
\end{align*}   

\begin{proposition}\label{prop:3.3}
    Let $dL_t^a(X)$ be the measure associated with the increasing process $L_t^a(X)$.
    Then $dL_t^a(X)$ is supported on $\{s\geq 0\mid X_s=a\}$.\marginnote{But this is not necessarily the full support!}
\end{proposition}

\begin{proof}
    Let $Y_t=|X_t-a|$.
    \[\implies Y_t^2=(X_t-a)^2\stackrel{\text{Itô to }f(X_t)=(X_t-a)^2}{=}(X_0-a)^2+\int_0^t (X_s-a)dX_s+2\langle X\rangle_t\] 
    \begin{align*}%TODO FIX
        Y_t^2\stackrel{\text{Itô to }f(Y_t)=Y_t^2}{=}&(X_0-a)^2+2\int_0^t \underbrace{Y_s dY_s}_{=|X_s-a|\cdot(\sgn(X_s-a)dX_s+dL_s^a(X))} + \underbrace{\langle Y \rangle_t}_{\langle X\rangle_t\text{ by prop \ref{prop:3.1}}}\\
        &=(X_0-a)^2+2\int_0^t(X_s-a)dX_s+2\int_0^t |X_s-a|dL_s^a(X)+\langle X\rangle_t\\
        \implies&\int_0^t |X_s-a|dL_s^a(X)=0
    \end{align*}
    and therefore the support is indeed contained in $\{s\geq 0\mid X_s=a\}$
\end{proof}

\begin{remark}
    If $f$ is convex $\implies f_-'(x)$ is increasing and left continuous.
    Therefore there exists a unique measure $f''(dx)$ on $\R_+$ such that 
    \[f''([a,b])=f_-'(b)-f_-'(a)\]
    If $f\in C^2(\R)$, then $f''(dx)=f''(x)dx$, i.e. it has the density given by the second derivative.

    For all convex functions $f$ with $f''(dx)=0$ for all $|x|\geq K$
    \[\implies \exists \alpha,\beta\in\R: f(x)=\alpha+\beta x+\frac{1}{2}\int_\R |x-a|f''(da)\]
    and $f_-'(x)=\beta+\frac{1}{2}\int_\R\sgn(x-a)f''(da)$ in a weak sense.
\end{remark}

\beginlecture{12}{04.06.24}

\begin{theorem}[Itô-Tanaka-formula]\label{thm:3.4}
    If $f$ is a difference of convex functions, $X$ is a continuous semimartingale
    \[\implies f(X_t)f(X_0)+\int_0^t f_-'(X_s)dX_s +\frac{1}{2}\int_R L_t^a(x)f''(da)\],
    where $f''(da)$ is the measure associated with $f_-'$.
\end{theorem}

\begin{proof}[Sketch of proof]
    (Full proof: Thm 9.6 LeGall book)

    Once localized $\to$ assume $f''(da)=0$ on $[-\kappa,\kappa]^c$

    \begin{align*}
        \implies f(X_t)&=\alpha + \beta X_t+ \int_{-\kappa}^\kappa |X_s-a|f''(da)\\
        & \stackrel{\text{prop. \ref{prop:3.2}}}{=}\alpha +\beta X_t + \frac{1}{2}\int |X_0-a|f''(da)+\frac{1}{2}\int\int_0^t \sgn(X_s-a)dX_s f''(da)+\frac{1}{2}\int L_t^a(X)f''(da)\\
        &=\underbrace{\alpha+\beta X_0+\frac{1}{2}\int |X_0-a|f''(da)}_{=f(X_0)}+\underbrace{\beta\int_0^t dX_s+\frac{1}{2}\int_0^t\int \sgn(X_s-a)f''(da)dX_s}_{=\int_0^1 f_-'(X_sdX_s)}+\frac{1}{2}\int L_t^a f''(da)
    \end{align*}

\end{proof}


\begin{corollary}[Occupation time formula]\label{cor:3.5}
    Almost surely, $\forall t\geq 0$, \underline{non-negative} measurable function $\varphi$
    \[\int_0^t\varphi(X_s)d\langle X\rangle_s=\int_\R\varphi (a)L_t^a(X)da\]
\end{corollary}

\begin{aexample}
    $X=$BM, $\varphi(X)=1_A(X)$, $A$ Borel set in $\R$
    \[\implies \int_0^t 1_A(X_s)ds\]
    is the time spend by $(X_s,s\in[0,t])$ in $A$ and the RHS is\marginnote{Think $A=[a,a+\epsilon]$}
    \[\int_A L_t^a(X)da\]
    $\implies L_t^a$ density of time spend by Brownian motion in $a$.
\end{aexample}

\begin{proof}
    (For $\varphi$ with bounded support)
    
    Find $f\in C^2$ s.t. $f''(x)=\varphi(x)$. \marginnote{Take $f$ as the twice integrated $\varphi$ on the support of $\varphi$ until $x$}

    $\implies$ Itô-Tanaka-formula: 
    \[f(X_t)=f(X_0)+\int_0^t f_-'(X_s)dX_s+\frac{1}{2}\int L_t^a(X)\varphi(a)da\]
    By Itô-formula:
    \[f(X_t)=f(X_0)+\int_0^t f'(X_s)dX_s+\frac{1}{2}\int_0^t\varphi(X_s)d\langle X\rangle_s\]
    The claim follows from comparing the terms.
\end{proof}

Explicit representation of the local time:

\begin{lemma}\label{lem:3.6}
    Let $X$ be a continuous semimartingale

    $\implies$ a.s. $\forall a\in\R,t\geq 0$:
    \[L_t^a(X)=\lim_{\epsilon\downarrow 0}\frac{1}{\epsilon}\int_0^t1_{a\leq X_s\leq a+\epsilon}d\langle X\rangle_s\]
\end{lemma}


\begin{proof}
    Take $\varphi(x)=\frac{1}{\epsilon}1_{[a\leq X\leq a+\epsilon]}$ in corollary \ref{cor:3.5}:\marginnote{See Thm 9.4 in LeGall for more details}
    \[\implies \frac{1}{\epsilon}\int_0^t1_{a\leq X_s\leq a+\epsilon}d\langle X\rangle_s=\frac{1}{\epsilon}\int_a^{a+\epsilon}L_t^{\tilde{a}}(X)d\tilde{a}\stackrel{\tilde{a}\to L_t^{\tilde{a}}}{=}L_t^a(X)\qedhere\]
\end{proof}

Similarly: 
\[\lim_{\epsilon\downarrow 0}\frac{1}{\epsilon}\int_0^t 1_{[a-\epsilon\leq X_s<a]}d\langle X\rangle_s = L_t^{a_-}(X)\]
\[\implies \lim_{\epsilon\downarrow 0}\frac{1}{2\epsilon}\int_0^t 1_{[a-\epsilon\leq X_s\leq a+\epsilon]}d\langle X\rangle_s=\frac{1}{2}(L_t^{a_-}(X)+L_t^a(X))\]
\begin{align*}
    L_t^a(X)-L_t^{a_-}(X)\stackrel{\text{prop \ref{prop:3.2}}}{=}& |X_t-a|-|X_0-a|-\int_0^t \sgn(X_s-a)dX_s-(|X_t-a_-|-|X_0-a_-|-\int_0^t \sgn(X_s-a_-)dX_s)\\
    =&2\int_0^t 1_{X_s=a}dX_s\stackrel{X_t=M_t+A_t}{=}2\int_0^t 1_{X_s=a}dA_s
\end{align*}
where the first two terms are equal, since $X$ is a continuous semimartingale. This then implies, if $X$ is a martingale (and therefore $A_t=0$)
then $L_t^a(X)=L_t^{a_-}(X)\implies L_t^a(X)=\lim_{\epsilon\downarrow 0}\frac{1}{2\epsilon}\int_0^1 1_{[a-\epsilon\leq X_s\leq a+\epsilon]}d\langle X \rangle_s$.

In particular, if $X$ is a BM: 
\[L_t^{a_-}(X)\implies L_t^a(X)=\lim_{\epsilon\downarrow 0}\frac{1}{2\epsilon}\int_0^1 1_{[a-\epsilon\leq X_s\leq a+\epsilon]}ds\]

\section{Brownian motion and local time}

Let $B$ be a standard BM, then by Tanaka: 
\[|B_t|=|\underbrace{B_0}_{=0}|+\int_0^t \sgn(B_s)dB_s+\underbrace{L_t}_{\coloneqq L_t^0(B)}\]
We want to define the process $R_t=|B_t|$ be the \dhighlight{BM reflected at $0$}.

We want to study $R_t$ and $S_t^B\coloneqq \sup_{0\leq s\leq t} B_s,L_t(B)$

\subsection{No strong solution of the Tanaka SDE}

\[(\star)=\begin{cases}
    dX_t &= \sgn(X_t)dB_t\\
    X_0&=0
\end{cases}\]
We already know: $B_t\coloneqq \int_0^t \sgn(W_s)dW_s$, where $W$ is a BM $\implies BM$ is a BM (using Levy characterization)
and \[\int_0^t\sgn(W_s)dB_s=\int_0^t \sgn(W_s)^2dW_s=W_t\to \sgn(W_t)dB_t=dW_t\]
and therefore $(W,B)$ is a weak solution of $(\star)$.

Assume $(X,B)$ is a strong solution of $(\star)\implies dX_t=\sgn(X_t)dB_t$ with $X$ is a BM. 

Itô-Tanaka-formula:

\begin{align*}
    |X_t|=\int_0^t\sgn(X_s)dX_s+L_t^0(X)\\
    \implies \int_0^t\sgn(X_s)dX_s=|X_t|-L_t^0(X)=|X_t|-\lim_{\epsilon\downarrow 0}\frac{1}{2\epsilon}\int_0^t 1_{|X_s|\leq \epsilon}ds\in \cF_t^{|X|}
\end{align*}

But also: 
\begin{align*}
    \int_0^t \sgn(X_s)dX_s = \int_0^t(\sgn(X_s))^2 d B_s=B_t
\end{align*}

\[B_t=|X_t|-\lim_{\epsilon\downarrow 0}\frac{1}{2\epsilon}\int_0^t1_{|X_s|\leq \epsilon}ds\]
$\implies B_t$ is $\cF_t^{|X|}$-measurable and therefore $B$ is $\cF^{|X|}$ measurable.


If $(X,B)$ is a strong solution, then $X$ is measurable w.r.t. $\cF^B$.
$\implies \cF^X\subset \cF^B\subseteq \cF^{|X|}$
which is wrong, since we can not recall the value of $X$ knowing only its absolute value.

\subsection{Reflected SDE}

\begin{definition}\label{def:3.7}
    The family $(X,l,W)$ is a weak solution of the \dhighlight{reflected SDE} (One-dimensional):
    \[dX_t=dW_t+dl_t\]
    if: 
    \begin{itemize}
        \item $W$ is a BM 
        \item $X$ is a \underline{positive} continuous process 
        \item $l$ is a \underline{positive non-decreasing} continuous process 
    \end{itemize}
    s.t. 
    \[\int_0^\infty 1_{X_s}>0d l_s=0\]
    The solution is called \dhighlight{strong}, if $(X,l)$ is adapted to $W$.
\end{definition}

\begin{aexample}
    \begin{itemize}
        \item $X_t\coloneqq |B_t|$
        \item $W_t\coloneqq \int_0^t\sgn(B_s)dB_s$
        \item $l_t=L_t^0(B)$
    \end{itemize}
    This is a weak solution of the \dhighlight{1 dimensional reflected SDE}. 
\end{aexample}

\beginlecture{13}{06.06.24}

\begin{lemma}[Skorokhod lemma for uniqueness of reflected SDE]\label{lem:3.8}
    Let $Y(t)$ be a continuous function with $y(0)\geq 0$. Then there exist a unique 
    pair $(z,a)$ of functions:
    \begin{itemize}
        \item  both continuous
        \item $a(0)=0,a$ is non-decreasing s.t.\begin{enumerate}
            \item[(a)] $z(t)=y(t)+a(t)$
            \item[(b)] $\int_0^\infty 1_{z(s)>0}da(s)=0$ 
        \end{enumerate}
    \end{itemize}
    Moreover, the function $a$ has the representation
    \[a(t)=\sup_{0\leq s\leq t}[y(s)]_-=\sup_{0\leq s\leq t}\max\{0,-y(s)\}\]
\end{lemma}

\begin{proof}
    Postponed :)
\end{proof}

Consequence of Lemma \ref{lem:3.8}:

\begin{align*}
    l_t(\omega)\coloneqq \sup_{0\leq s\leq t}(-W_s(\omega))_+=\sup_{0\leq s\leq t}(-W_s(\omega))\eqqcolon S_t^{-W}(\omega)
\end{align*}

given $W(\omega), X_t(\omega)=W_t(\omega)+l_t(\omega)=W_t(\omega)+\sup_{0\leq s\leq t}(-W_s(\omega))$.

$\implies \exists!$ strong solution of the reflected SDE.
Notation: \marginnote{We can start with $W$ and explicitly construct a strong solution!}
\[R_t\coloneqq |B_t|=W_t+L_t=W_t+S_t^{-W}\] 

\begin{theorem}\label{thm:3.9}
    \begin{align*}
        \text{Law}(|B|,\underbrace{L}_{=L^0(B)})&\stackrel{(1)}{=}\text{Law}(L+W,L)\\
        &\stackrel{(2)}{=}\text{Law}(W+S^{-W},S^{-W})\\
        &\stackrel{(3)}{=}\text{Law}(S^{-\tilde{W}}-\tilde{W},S^{\tilde{W}})
    \end{align*}
    with $\tilde{W}$ a generic BM.
\end{theorem}

\begin{proof}
    $(1)$ is from $R_t=|B_t|=W_t+L_t^{0}(B)$ (as a process)

    $(2)$ by the skorokhod representation: $L_t=S_t^{-W}$

    $(3)$ $W\stackrel{d}{=}-\tilde{W}$
\end{proof}

$\forall t\geq 0$:
\marginnote{Something is wrong here? Or at the very least confusing}
\[S_t\coloneqq \sup_{0\leq s\leq t} B_s\stackrel{(d)}{=}|B_t|\stackrel{(d)}{=}L_t^0(B)\]

By the reflection principle:
\begin{align*}
    \bP(S_t\in dx,B_t\in dy)\stackrel{2.2\text{ LeGall}}{=} \frac{2(2x-y)}{\sqrt{2\pi t^3}}e^{-\frac{(2x-y)^2}{2t}}1_{x>0,y<x}dxdy
\end{align*}
and 
\begin{align*}
    \text{Law}(|B|)=\text{Law}(S^W-W)
\end{align*}

Two points of view:

1. $B\to \R_t\coloneqq |B_t|,W_t\coloneqq\int_0^t\sgn(B_s)dB_s,L_t\coloneqq L_t^0(B)$ satisfies\[R_t=W_t+L_t\]

2. Given $W_t$ ($\forall \omega$): Define $l_t\coloneqq\Phi_t(W)=\sup_{0\leq s\leq t} (-W_s),X_t=W_t+l_t$

Law$(R,L)=\text{Law}(X,l)$.

An alternative definition of reflected Brownian motion is \[X_t\coloneqq \underbrace{W_t+\Phi_t(W)}_{\text{\dhighlight{Skorokhod map}}}\]

\begin{aremark}
    Careful:
    \[|W_t(\omega)|\neq W_t(\omega)+\Phi_t(W(\omega))\]
    Or
    \[z(t)\neq |y(t)|\]
\end{aremark}

\section{Reflected BM on a curve}

In section 3.2, we have reflected BM on $g(t)=0\forall t\geq 0$.
\[X_t=W_t+\sup_{0\leq s\leq t}(-W_s)\]
Skorokhod lemma; from continuous function $y(t),y(0)\geq 0$:
\[z(t)\coloneqq y(t)+\sup_{0\leq s\leq t}(y(s)-0)_-\] 

Let $D_g\coloneqq \{(x,t) \mid x\geq g(t)\}$.\marginnote{$D_g$ is the space above the curve $(t,g(t))$, not sure why the coordinates are fliped tho?}

Let $(W_t)_{t\geq 0}$ with $W_0\geq g(0)$, then there exists a unique, continuous non-decreasing process $L_t$ with $L_0=0$ s.t.
\[X_t\coloneqq W_t+L_t\geq g(t)\forall t\geq 0\]
and $L_t$ may increase only when $X_t$ is at the boundary of $D_g$.
\[\int_0^\infty1_{(g(s),\infty)}(X_s)dL_s=0\]
$X_t$ has the formula:
\[L_t=\sup_{0\leq s\leq t}(W_s-g(s))_-\]
To see this claim: Consider $\tilde{W}_t=W_t-g(t)$
\[\implies \tilde{X}_t\coloneqq X_t-g(t)\]
is constructed by the Skorokhod map and \[\tilde{X}_t=\tilde{W}_t+L_t\geq 0\]

\begin{definition}\label{def:3.10}
    The \dhighlight{BM reflected by a continuous function $g(t)$} with $X_0\geq g(0)$ is given by 
    the following construction \begin{itemize}
        \item Given $W$ a BM with $W_0=X_0\geq g(0)$, define \[X_t\coloneqq W_t+\sup_{0\leq s\leq t}(W_s-g(s))_-\]
        \item  Alternatively with $W_0=0:$\[X_t=X_0+W_t+\sup_{0\leq s\leq t}(W_s-g(s))_-\]
    \end{itemize}
\end{definition}

\begin{aremark}
    Think about sticky BM, which is the limit of some random walk which stays on the boundary with some positive probability.

    The exercise talks shows two reflected BMs, whose difference lies in the Weil chamber and solves the SDE for a process conditioned to be positive forever.
\end{aremark}

SDE: $dX_t=dW_t+dL_t$ or $X_t=X_0+\underbrace{W_t}_{W_0=0}+L_t^g(X)$, where 
$L_t^g(X)$ is the local time of $X$ spend at the function $g$.

\begin{aexample}\marginnote{Start with 2-dim BM then define the reflected BM...}
    Let $B=(B_1(t),B_2(t))$ a 2-dimensional BM with $B_1(0)\leq B_2(0)$ s.t. $B_1$ is not depending on $B_2$, but $B_2$ is reflected upwards by $(B_1(t),t\geq 0)=g$

    $\implies (B_1(t),\tilde{B}_2(t))\in D=\{(x_1,x_2\in\R^d\mid x_1\leq x_2)\}$
\end{aexample}

\begin{proposition}\label{prop:3.11}
    Denote by $p_t(x,y)$ be the transition probe density of $B$:\[p_t(B_1(t)\in dy_1, \tilde{B}_2(t)\in dy_2\mid B_1(0)=0,\tilde{B}_2(0)=x_2)=p_t((x_1,x_2),(y_1,y_2))dy_1dy_2\] 

    It satisfies the following equations:
    \begin{align*}
        \frac{1}{2}\left(\frac{\partial^2}{\partial x_1^2}+\frac{\partial^2}{\partial x_2^2}\right)p_t((x_1,x_2),(y_1,y_2))=\frac{\partial}{\partial}p_t((x_1,x_2),(y_1,y_2))
    \end{align*}
    for $(x_1,x_2),(y_1,y_2)\in D\setminus \partial D,t>0$.
    \begin{align*}
        p_t((x_1,x_2),(y_1,y_2))dy_1dy_2\stackrel{t\to0}{\to}\delta_{x}(y)
    \end{align*}
    as well as 
    \[\frac{\partial}{\partial x_2}p_t(x,y)\mid_{x=y}=0\]

\end{proposition}

\begin{proof}\marginnote{Important information: where is the boundary condition coming from? Not immediatly obvious!}
    Let $g$ be any smooth test function in $D$, set $f(t,x)\coloneqq \int dy g(y)p_t(x,y)$. The undefined integrals are over $D$, for Itô we assume $f\in C^2$.

    (1) SDE: \[\begin{cases}
        dB_t^1=dW_t^1\\
        d\tilde{B}_t^2=dW_t^2+dL_t^{B^1}(\tilde{B}_2)
    \end{cases}\]
    By Itô: Let $0\leq t\leq T$:
    \begin{align*}
        &f(T-t,B-t)\\
        &=f(T,B_0)+\int dy g(y)[-\dot{P}_{T-S}(B_s,y)ds]+\int dy g(y)\int_0^t \partial x_1 p_{T-S}(B_s,y)dW_s^1\\
        &+\int_0^t \partial x_2 p_{T-S}(B_s,y)(dW_s^1+dL_s)\\
        &+ \int dy g(y)\left[\frac{1}{2}\int_0^t\left(\frac{\partial^2}{\partial x_1^2}+\frac{\partial^2}{\partial x_2^2}p_{T-S}(B_s,y)ds\right)\right]
    \end{align*}
    (2) Martingale: Let $t\leq T$
    \begin{align*}
        \bE(g(B_t)\mid \cF_t)\stackrel{\text{MP}}{=}&\bE(g(B_t)\mid B_t)\\
        &=\int dy g(y)p_{T-t}(B_t,y)=\underbrace{f(T-t,B_t)}_{\text{Martingale}}
    \end{align*}
\end{proof}


